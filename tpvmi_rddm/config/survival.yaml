# ==========================================
# Training Hyperparameters
# ==========================================
train:
  epochs: 300
  batch_size: 64
  eval_batch_size: 1024
  lr: 0.0001 # 0.01 would be a good start for SGD
  val_ratio: 0
  val_interval: 100
# ==========================================
# Diffusion Model Architecture & Schedule
# ==========================================
diffusion:
  diffusion_embedding_dim: 128
  num_steps: 50
  sum_scale: 0.1
# ==========================================
# Model Feature Embeddings
# ==========================================
model:
  featureemb: 64
  channels: 64
  nheads: 8
  layers: 3
  dropout: 0.1 # if dropout is enabled, more epochs are required.
# ==========================================
# Testing / Imputation
# ==========================================
else:
  task: "Res-N"
  m: 5
  mi_approx: "dropout" # switching between "SWAG", "dropout", "bootstrap", "None"
                       # "SWAG" is very unstable due to SGD optimizer
                       # "dropout" may lose some uncertainty
                       # "bootstrap" is slow
