# ==========================================
# Training Hyperparameters
# ==========================================
train:
  epochs: 500
  batch_size: 128
  eval_batch_size: 1024
  lr: 0.0001 # 0.01 would be good for SGD
  val_ratio: 0
  val_interval: 100
# ==========================================
# Diffusion Model Architecture & Schedule
# ==========================================
diffusion:
  diffusion_embedding_dim: 128
  beta_start: 0.0001
  beta_end: 0.02
  num_steps: 50
  schedule: "linear"

# ==========================================
# Model Feature Embeddings
# ==========================================
model:
  featureemb: 64
  channels: 128
  nheads: 4
  layers: 3
  dropout: 0.05 # if dropout is enabled, more epochs are required.
# ==========================================
# Testing / Imputation
# ==========================================
else:
  m: 5
  mi_approx: "dropout" # switching between "SWAG", "dropout", "bootstrap", "None"
                       # "SWAG" is very unstable due to SGD optimizer
                       # "dropout" may lose some uncertainty
                       # "bootstrap" is slow
